{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "urkAI4cYhkae"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import nltk "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "KY2NW7YIhkaj"
   },
   "outputs": [],
   "source": [
    "def load_data(split_name='train', columns=['text', 'stars'], folder='data'):\n",
    "    '''\n",
    "        \"split_name\" may be set as 'train', 'valid' or 'test' to load the corresponding dataset.\n",
    "        \n",
    "        You may also specify the column names to load any columns in the .csv data file.\n",
    "        Among many, \"text\" can be used as model input, and \"stars\" column is the labels (sentiment). \n",
    "        If you like, you are free to use columns other than \"text\" for prediction.\n",
    "    '''\n",
    "    try:\n",
    "        print(f\"select [{', '.join(columns)}] columns from the {split_name} split\")\n",
    "        df = pd.read_csv(f'{folder}/{split_name}.csv')\n",
    "        df = df.loc[:,columns]\n",
    "        print(\"Success\")\n",
    "        return df\n",
    "    except:\n",
    "        print(f\"Failed loading specified columns... Returning all columns from the {split_name} split\")\n",
    "        df = pd.read_csv(f'{folder}/{split_name}.csv')\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1PpXKh0Bhkak",
    "outputId": "28edefdb-adf1-49d3-e322-3e8f28b2ea55"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "select [text, stars] columns from the train split\n",
      "Success\n",
      "select [text, stars] columns from the valid split\n",
      "Success\n",
      "select [text, stars] columns from the test split\n",
      "Failed loading specified columns... Returning all columns from the test split\n"
     ]
    }
   ],
   "source": [
    "train_df = load_data('train', columns=['text', 'stars'])\n",
    "valid_df = load_data('valid', columns=['text', 'stars'])\n",
    "# the test set labels (the 'stars' column) are not available! So the following code will instead return all columns\n",
    "test_df = load_data('test', columns=['text', 'stars'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text):\n",
    "    \"\"\"\n",
    "    :param text: a doc with multiple sentences, type: str\n",
    "    return a word list, type: list\n",
    "    e.g.\n",
    "    Input: 'Text mining is to identify useful information.'\n",
    "    Output: ['Text', 'mining', 'is', 'to', 'identify', 'useful', 'information', '.']\n",
    "    \"\"\"\n",
    "    return nltk.word_tokenize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "okulinf-hkap"
   },
   "outputs": [],
   "source": [
    "# Prepare the data.\n",
    "# As an example, we only use the text data. \n",
    "x_train = train_df['text']\n",
    "y_train = train_df['stars']\n",
    "  \n",
    "x_valid = valid_df['text']\n",
    "y_valid = valid_df['stars']\n",
    "\n",
    "x_test = test_df['text']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "K2HwaFTfhkau"
   },
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer(tokenizer=tokenize) \n",
    "lr2 = LogisticRegression()\n",
    "steps = [('tfidf', tfidf),('lr', lr2)]\n",
    "pipe2 = Pipeline(steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "mcdeaTm4_S73"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Penalty: l2\n",
      "Best C: 1.2067926406393288\n",
      "Max df: 0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "c = np.logspace(-4, 4, 50)\n",
    "penalty = ['l2']\n",
    "max_df = [0.25, 0.5, 0.75]\n",
    "parameters = dict(tfidf__max_df = max_df, lr__C = c, lr__penalty = penalty)\n",
    "clf_GS = GridSearchCV(pipe2, parameters, cv=2, n_jobs=-1)\n",
    "best_clf = clf_GS.fit(x_train, y_train)\n",
    "\n",
    "print('Best Penalty:', clf_GS.best_estimator_.get_params()['lr__penalty'])\n",
    "print('Best C:', clf_GS.best_estimator_.get_params()['lr__C'])\n",
    "print('Max df:', clf_GS.best_estimator_.get_params()['tfidf__max_df'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "BcaUsWEq_S73"
   },
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer(tokenizer=tokenize, max_df=0.75, ngram_range=(1,2)) \n",
    "lr2 = LogisticRegression(C=159.99, penalty='l2')\n",
    "steps = [('tfidf', tfidf),('lr', lr2)]\n",
    "pipe2 = Pipeline(steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "yI6uNeWL_S73",
    "outputId": "df5ce5a6-cba5-4874-eb59-427f1667f3bb"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('tfidf',\n",
       "                 TfidfVectorizer(max_df=0.75, ngram_range=(1, 2),\n",
       "                                 tokenizer=<function tokenize at 0x7f9ea135ce50>)),\n",
       "                ('lr', LogisticRegression(C=159.99))])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe2.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "JNsAq17l_S74",
    "outputId": "6720984c-a32a-4247-8c3b-ed8f46e3af3d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1     0.7209    0.8333    0.7730       282\n",
      "           2     0.3398    0.2574    0.2929       136\n",
      "           3     0.4633    0.3868    0.4216       212\n",
      "           4     0.5199    0.4764    0.4972       466\n",
      "           5     0.7766    0.8308    0.8028       904\n",
      "\n",
      "    accuracy                         0.6625      2000\n",
      "   macro avg     0.5641    0.5569    0.5575      2000\n",
      "weighted avg     0.6460    0.6625    0.6523      2000\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "[[235  24   9   3  11]\n",
      " [ 45  35  37  14   5]\n",
      " [ 20  31  82  62  17]\n",
      " [ 11  12  38 222 183]\n",
      " [ 15   1  11 126 751]]\n",
      "accuracy 0.6625\n"
     ]
    }
   ],
   "source": [
    "y_pred = pipe2.predict(x_valid)\n",
    "print(classification_report(y_valid, y_pred, digits = 4))\n",
    "print(\"\\n\\n\")\n",
    "print(confusion_matrix(y_valid, y_pred))\n",
    "print('accuracy', np.mean(y_valid == y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "49ag2BEohkax"
   },
   "source": [
    " We find the second model (pipe2) has higher accuracy, then we use the second model to make predictions on test data. In practice, you may not only focus on the accuracy, but also other metrics (precision, recall, f1), since the label distribution is not always balanced."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j9u6IS-zhkay"
   },
   "source": [
    "### (3) Generate predictions on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "wnGE7tlIhkaz"
   },
   "outputs": [],
   "source": [
    "predict_test = pipe2.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "9tn9e6S-hka0",
    "outputId": "e8544feb-6b62-4fe2-8681-e94289544cab"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 5, 1, ..., 1, 1, 2])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "iRDFD6ADhka1"
   },
   "outputs": [],
   "source": [
    "pred_df = pd.DataFrame({'stars': predict_test, 'review_id': test_df['review_id']})\n",
    "pred_df.to_csv('pred.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y5IV6ozYhka2"
   },
   "source": [
    " Then you may submit the predictions `pred.csv` on the test set. "
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "logistic_regression.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
